{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/LangChain_AI_Image_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9iqJ8-RM_2Q",
        "outputId": "e50ca756-99ca-4bb5-c169-c8fb8df181dd"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWAHCTE7oa8F"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojv0fTD_oqxj"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] or 'Your OPENAI API Key'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVwq0-yHoczv"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model_name='gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKk388MbGLKs"
      },
      "source": [
        "# CUDA\n",
        "\n",
        "CUDA is a parallel computing platform and programming model created by NVIDIA. With more than 20 million downloads to date, CUDA helps developers speed up their applications by harnessing the power of GPU accelerators. \n",
        "\n",
        "https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/\n",
        "\n",
        "# BLIP\n",
        "\n",
        "The BLIP model was proposed in BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.\n",
        "\n",
        "BLIP is a model that is able to perform various multi-modal tasks including\n",
        "\n",
        "    Visual Question Answering\n",
        "    Image-Text retrieval (Image-text matching)\n",
        "    Image Captioning\n",
        "\n",
        "https://huggingface.co/docs/transformers/model_doc/blip\n",
        "\n",
        "# Image to Text HuggingFace Model\n",
        "\n",
        "Model card for image captioning pretrained on COCO dataset - base architecture (with ViT large backbone).\n",
        "\n",
        "https://huggingface.co/Salesforce/blip-image-captioning-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4L90-HwuH5V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "image_to_text_model = \"Salesforce/blip-image-captioning-large\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(image_to_text_model)\n",
        "model = BlipForConditionalGeneration.from_pretrained(image_to_text_model).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-HRSdY_HsbE"
      },
      "outputs": [],
      "source": [
        "from transformers.models.oneformer.modeling_oneformer import OneFormerModelOutput\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "def describeImage(image_url):\n",
        "  image_object = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "  # image\n",
        "  inputs = processor(image_object, return_tensors=\"pt\").to(device)\n",
        "  outputs = model.generate(**inputs)\n",
        "  return processor.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxxvzqttuOZG"
      },
      "outputs": [],
      "source": [
        "description = describeImage('https://images.unsplash.com/photo-1673207520321-c27d09eb0955?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1035&q=80')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qTL13DM1uU3e",
        "outputId": "35111030-38be-40f6-9e9f-0dbd55ea7744"
      },
      "outputs": [],
      "source": [
        "description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFPyDKY0ufLs"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import BaseTool\n",
        "\n",
        "class DescribeImageTool(BaseTool):\n",
        "    name = \"Describe Image Tool\"\n",
        "    description = 'use this tool to describe an image.'\n",
        "\n",
        "    def _run(self, url: str):\n",
        "        description = describeImage(url)\n",
        "        return description\n",
        "    \n",
        "    def _arun(self, query: str):\n",
        "        raise NotImplementedError(\"Async operation not supported yet\")\n",
        "\n",
        "tools = [DescribeImageTool()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HLzqZbzMHwH"
      },
      "source": [
        "# LangChain Agent Types\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html\n",
        "\n",
        "## chat-conversational-react-description\n",
        "\n",
        "a specific type of agent (chat-conversational-react-description) which expects to be used with a memory component.\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkUISONKCMGQ"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        "    memory=ConversationBufferWindowMemory(\n",
        "        memory_key='chat_history',\n",
        "        k=5,\n",
        "        return_messages=True\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJPk8RebvGC3",
        "outputId": "6e3f3bff-fbcd-4289-f30b-c2dc9c4915ef"
      },
      "outputs": [],
      "source": [
        "image_url = 'https://images.unsplash.com/photo-1673207520321-c27d09eb0955?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1035&q=80'\n",
        "agent(f\"Describe the following image:\\n{image_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBPVaqbIQpoG",
        "outputId": "12bb59a8-0c68-4def-9628-c0224ba54dad"
      },
      "outputs": [],
      "source": [
        "agent(f\"What is the brand of car in the following image:\\n{image_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlJvM2UrhkWT",
        "outputId": "25b4bc7f-4209-4df7-bbfe-75b27971a404"
      },
      "outputs": [],
      "source": [
        "image_url = 'https://images.unsplash.com/photo-1682228287072-5e23cbffd487?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=987&q=80'\n",
        "agent(f\"Please describe the following image:\\n{image_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g0ri68KEC0q",
        "outputId": "299ca2f3-0845-4cdf-fcc2-fa537bdf4169"
      },
      "outputs": [],
      "source": [
        "agent.memory.buffer"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOchX5gTlFsmwSKIkcaRitG",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
