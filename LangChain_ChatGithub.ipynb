{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/LangChain_ChatGithub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o-rPJYwWLh8",
        "outputId": "4952e7d1-8153-44a8-a0fc-00202ea37625"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain deeplake openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTRCqa1d0zSZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "os.environ['ACTIVELOOP_TOKEN'] = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbSQL7qq0_la"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(disallowed_special=())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciO_aYtP1EA3",
        "outputId": "3e510ab6-29bf-4cf4-aeb2-b49455dda961"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/chroma-core/chroma.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl3XkDfJ1eBl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "root_dir = './chroma'\n",
        "docs = []\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for file in filenames:\n",
        "        try: \n",
        "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
        "            docs.extend(loader.load_and_split())\n",
        "        except Exception as e: \n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPGsYWURF9i9",
        "outputId": "bae55e03-e096-4677-bea4-82ec227be093"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTMD_m6S1jpm",
        "outputId": "a0e1ab29-2fca-4c8a-e528-887b19441d02"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "011k3P5oGCEI",
        "outputId": "74b9fe1f-a1b7-407e-a95a-467c6de2a493"
      },
      "outputs": [],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVcjOx-N1oLu",
        "outputId": "2ea6a414-1e33-427c-87e2-c900b67ad07d"
      },
      "outputs": [],
      "source": [
        "username = \"wyang14\"\n",
        "db = DeepLake(dataset_path=f\"hub://{username}/chroma_source\", embedding_function=embeddings, public=True)\n",
        "db.add_documents(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMhy-xdn1vMw",
        "outputId": "ee0af4f0-c411-4f18-fd4d-349ac6374fa2"
      },
      "outputs": [],
      "source": [
        "db = DeepLake(dataset_path=\"hub://wyang14/chroma_source\", read_only=True, embedding_function=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLlxAZ4S10GE"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever()\n",
        "retriever.search_kwargs['distance_metric'] = 'cos'\n",
        "retriever.search_kwargs['fetch_k'] = 100\n",
        "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retriever.search_kwargs['k'] = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsKsATuG190J"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "model = ChatOpenAI(model='gpt-3.5-turbo')\n",
        "qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xhQH_VG2BZf",
        "outputId": "992d296f-a3eb-4041-e7de-a56e392be261"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What does Chroma do?\",\n",
        "    \"How to use Chroma?\"\n",
        "] \n",
        "chat_history = []\n",
        "\n",
        "for question in questions:  \n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    chat_history.append((question, result['answer']))\n",
        "    print(f\"Question:\\n {question} \\n\")\n",
        "    print(f\"Answer:\\n {result['answer']} \\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_DYKLNmBrPK"
      },
      "outputs": [],
      "source": [
        "def ask(question, chat_history):\n",
        "  response = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "  print(f\"Question:\\n {question}\\n\")\n",
        "  print(f\"Answer:\\n {response['answer']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ6d_NJx4bsD",
        "outputId": "a7118a55-a206-4117-9323-b483a5d1f9b8"
      },
      "outputs": [],
      "source": [
        "ask(\"What's the main programming language used in Chroma?\", chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMNXbAS64xiy",
        "outputId": "a827dbf9-ee9c-48d4-8a7f-5ccf78ad03c6"
      },
      "outputs": [],
      "source": [
        "ask('Summarize the storage part of Chroma', chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpcokdnz4_7R",
        "outputId": "027ee649-b309-4b6c-aea7-541ccd92153c"
      },
      "outputs": [],
      "source": [
        "ask('Tell me more about Sentence Transformers', chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrLDPlJB9LxB",
        "outputId": "3b22cd38-f510-4591-a884-deec3c3b07ea"
      },
      "outputs": [],
      "source": [
        "ask('Show me some example code on how to use Chroma to store embeddings', chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23vpHyrY-sMv",
        "outputId": "dafa707e-8857-4487-e6bc-9fac4ae80bd6"
      },
      "outputs": [],
      "source": [
        "ask('What is the Python class for Chroma query interface?', chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw2V0-pa_AAp",
        "outputId": "ad403141-77d2-4c7c-9383-e0f373e1045f"
      },
      "outputs": [],
      "source": [
        "ask('Show me the public functions of class Client', chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDG3CTK5AftH",
        "outputId": "15e696d2-86bf-434a-be50-1dc4eff5899e"
      },
      "outputs": [],
      "source": [
        "ask('What are the underlying databases used by Chroma?', chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reZAo8xPAvQg",
        "outputId": "d1f1ebaf-52fb-4274-93ee-ffd131d41052"
      },
      "outputs": [],
      "source": [
        "ask('Which class implements the DuckDB support?', chat_history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNnHgC0INV5gC+75pBfvvrl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
